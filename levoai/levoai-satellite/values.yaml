replicaCount: 1
resources: {}
# We usually recommend not to specify default resources and to leave this as a conscious
# choice for the user. This also increases chances charts run on environments with little
# resources, such as Minikube. If you do want to specify resources, uncomment the following
# lines, adjust them as necessary, and remove the curly braces after 'resources:'.
# limits:
#   cpu: 100m
#   memory: 128Mi
# requests:
#   cpu: 100m
#   memory: 128Mi

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80
affinity: {}
global:
  imageRegistry: ""
  imagePullSecrets: []
  serviceAnnotations: {}
  virtualService:
    enabled: false
    fullyQualifiedDomainName: ""
    gateway: ""
  levoai:
    log_level: INFO
    mode: prod_k8s
    pi_detector_data_dir: "/opt/levoai/datasets/"
  levoai_config_override:
    rabbitmq:
      host: levoai-rabbitmq
      use_ssl: false
    kafka:
      bootstrap_servers: levoai-kafka:9092
    onprem-api:
      # refresh-token: "" # # DEPRECATED: Do not set refresh-token via Helm values.
      #  # Instead, create a Kubernetes Secret (e.g., `levoai-satellite`) with the refresh-token
      #  # and reference it in your configuration.
      org-id: "" # org-id is required -- you must use helm --set global.levoai_config_override.onprem-api.org-id=O where O is a Levo.ai organization ID
      url: "https://api.levo.ai"
    tagger_ignore_seen_flows: true
    authentication_inspection: false # defaults to false. if we want to send over auth secrets, we must use helm --set global.levoai_config_override.authentication_inspection=true
    # By default, satellite will log raw traces at debug level. This can be controlled with the following parameter.
    # WARNING: leave this at debug unless you know what you are doing.
    traces_log_level: DEBUG
    api_rule_evaluation:
      enabled: true
    detection:
      enabled: false
    enable_ssl_cert_checks: true
    ignore_user_agents:
      - "levoai/"
      - "schemathesis/"
      - "kube-probe/"
      - "Prometheus/"
      - "Blackbox Exporter/"
  nodeSelector: {}
  tolerations: []
  podAnnotations: {}
  useRabbitmq: true
  useKafka: false
  busyboxImage: levoai/busybox
  multiTenancyEnabled: false
haproxy:
  enabled: true
  fullnameOverride: "levoai-haproxy"
  image:
    repository: levoai/haproxy
    tag: 0.2.10
  service:
    type: ClusterIP # Change to LoadBalancer to expose it
  satelliteAuthnEnabled: false
rabbitmq:
  fullnameOverride: "levoai-rabbitmq"
  # Override the dependency chart's image if needed
  image:
    registry: "docker.io"
    repository: "rabbitmq"
    tag: "3.13.7-management-alpine"
    pullPolicy: "IfNotPresent"
  persistence:
    enabled: true
    size: 32Gi
  extraConfiguration: |-
    heartbeat = 600
    disk_free_limit.absolute = 500MB
    tcp_listen_options.keepalive = true
    tcp_listen_options.nodelay = true
    tcp_listen_options.send_timeout = 120000
  extraEnvVars:
    - name: RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS
      value: "-rabbit consumer_timeout 600000"
    - name: RABBITMQ_ENABLED_PLUGINS_FILE
      value: "/bitnami/rabbitmq/mnesia/enabled_plugins"
    - name: RABBITMQ_DEFAULT_USER
      valueFrom:
        secretKeyRef:
          name: levoai-rabbitmq-auth
          key: rabbitmq-username
    - name: RABBITMQ_DEFAULT_PASS
      valueFrom:
        secretKeyRef:
          name: levoai-rabbitmq-auth
          key: rabbitmq-password
    - name: RABBITMQ_ERLANG_COOKIE
      valueFrom:
        secretKeyRef:
          name: levoai-rabbitmq-auth
          key: rabbitmq-erlang-cookie
  # NEW: Plugin setup configuration (uses same image as main container)
  pluginSetup:
    enabled: true
    plugins:
      - "rabbitmq_management"
    resources: {}
    securityContext: {}
  # REMOVE: The hardcoded initContainers section
  # initContainers: []
  configurationExistingSecret: ""
  configuration: |-
    loopback_users.guest = false
  auth:
    existingPasswordSecret: levoai-rabbitmq-auth
    existingErlangCookieSecret: levoai-rabbitmq-auth
    tls:
      autoGenerated: true
      enabled: true
      sslOptionsVerify: "verify_none"
      failIfNoPeerCert: false
  service:
    portEnabled: true
kafka:
  fullnameOverride: "levoai-kafka"
  # Override the kafka image to use bitnamilegacy
  image:
    registry: "docker.io"
    repository: "bitnamilegacy/kafka"
    tag: "3.5.0-debian-11-r21"
    pullPolicy: "IfNotPresent"
  # Kafka configuration for KRaft mode (no Zookeeper)
  kraft:
    enabled: true
  # Disable Zookeeper since we're using KRaft mode
  zookeeper:
    enabled: false
  # Number of Kafka nodes (single node for dev/test)
  replicaCount: 1
  # Listeners configuration
  listeners: []
  # Service configuration
  service:
    type: ClusterIP
    ports:
      client: 9092
  persistence:
    enabled: true
    size: 32Gi
satellite:
  fullnameOverride: "levoai-satellite"
  env: []
tagger:
  fullnameOverride: "levoai-tagger"
  env:
    - name: RUN_SEPARATE_PROCESSES
      value: "true"
testrunner:
  enabled: true
  fullnameOverride: "levoai-testrunner"
detection:
  enabled: false
